# 异常处理优化


| 时间         | 版本    | 内容   | 修改人  |
| ---------- | ----- | ---- | ---- |
| 2020/05/13 | 1.0.0 | 学习整理 | 王洪宾  |

## 一、异常种类

大的分类：Java 崩溃和Native 崩溃

 Java异常又可以细分IO，网络，权限，运行等。

​ Java的异常产生的原因一般比较容易理解，出现了未捕获异常，导致程序异常退出。Native 崩溃又是怎么产生的呢？一般都是因为在 Native 代码中访问非法地址，也可能是地址对齐出现了问题，或者发生了程序主动 abort，这些都会产生相应的 signal 信号，导致程序异常退出。

**相关指标**：

UV，PV Crash率

启动Crash率：影响最严重，结合客户端容灾

增量、存量crash率：增量是重点，存量需要持续追踪

**Crash关键参数**：目的就是尽量现场还原

堆栈、设备、OS版本、进程、线程、logcat

前后台、使用时长、app版本、小版本、渠道

cpu架构、内存信息、线程数、资源包、行为日志

**APM后台聚合**：

Crash现场信息；Crash Top机型、OS版本、分布版本、区域；起始版本、上报趋势、是否新增、持续、量级

**整体结构**：

采集层：错误堆栈、设备信息、行为日志、其他信息

处理层：数据清洗、数据聚合、维度分类、趋势对比

展示层：数据还原、维度信息、起始版本、其他信息

报警层：环比、同比、邮件、IM、电话

**Crash预防和治理**：

专项小组轮值，自动匹配分配、处理流程全纪录

单个Crash：根据堆栈及现场信息解决，找共性：机型，OS，实验开关、资源包；线下复现、远程调试。

Crash治理：解决线上常规Crash；系统级Crash尝试Hook绕过；疑难crash重点突破、更换方案



## 二、异常捕获

### 1.Java层的异常

​	最重要的是主线程异常，这个必须捕获和处理的，会引起用户使用的问题，需要及时收集，分析，修复。网上有很多资料可以查到，可以通过setDefaultUncaughtExceptionHandler自己注册异常Handler来实现处理，也可以Hook系统handler，当然还有最简单的就是接入第三方SDK，像bugly。

​        java层的异常可以从代码结构上预防，比如我们现在在项目中做 **安全组件**，就是统一对生命周期方法做监控，对系统API调用容易出错的地方做代理层，研发在开发的时候必须基于安全组件开发，一般不直接接触系统控件和方法。这样能统一收集和处理问题。

### 2.Native异常

​	如果你对 Native 崩溃机制的一些基本知识还不是很熟悉，建议你阅读一下[《Android 平台 Native 代码的崩溃捕获机制及实现》](https://mp.weixin.qq.com/s/g-WzYF3wWAljok1XjPoo7w).

​	捕获流程：

​	1）编译端。编译C/C++代码时，需要将带符号信息的文件保留下来。

​	2）客户端。捕获到崩溃时，将收集到尽可能多的有用信息写入到日志文件，然后选择合适的时机上传到服务器。

​	3）服务端。读取客户端上报的日志文件，寻找合适的符号文件，生成可读的C/C++调用栈。

​         ![native_crash_catch](..\images\native_crash_catch.jpg)

​	在Native层，由于C/C++野指针或者内存读取越界等原因，导致APP整个Crash的错误,这种Crash一般会在Logcat中打印出包含Fatal signal字样的日志。Native Crash都是基于Linux的信号处理机制，本质上是一种软件层面的中断机制，用来通知进程发生了异步事件。由于Native层Crash大部分都是signal软中断类型错误，只要捕获signal并进行处理，得到中断的具体信息就很好帮助定位了。这一步可以通过sigaction注册信号处理函数来完成。

​	Chromium 的Breakpad是目前 Native 崩溃捕获中最成熟的方案，

### 3.Native 崩溃捕获的难点

​	**最核心的是怎么样保证客户端在各种极端情况下依然可以生成崩溃日志**。因为在崩溃时，程序会处于一个不安全的状态，如果处理不当，非常容易发生二次崩溃。那么，生成崩溃日志时会有哪些比较棘手的情况呢？

#### 情况一：文件句柄泄漏，导致创建日志文件失败，怎么办？

应对方式：我们需要提前申请文件句柄 fd 预留，防止出现这种情况。

#### 情况二：因为栈溢出了，导致日志生成失败，怎么办？

应对方式：为了防止栈溢出导致进程没有空间创建调用栈执行处理函数，我们通常会使用常见的 signalstack。在一些特殊情况，我们可能还需要直接替换当前栈，所以这里也需要在堆中预留部分空间。

#### 情况三：整个堆的内存都耗尽了，导致日志生成失败，怎么办？

应对方式：这个时候我们无法安全地分配内存，也不敢使用 stl 或者 libc 的函数，因为它们内部实现会分配堆内存。这个时候如果继续分配内存，会导致出现堆破坏或者二次崩溃的情况。Breakpad 做的比较彻底，重新封装了Linux Syscall Support，来避免直接调用 libc。

#### 情况四：堆破坏或二次崩溃导致日志生成失败，怎么办？

应对方式：Breakpad 会从原进程 fork 出子进程去收集崩溃现场，此外涉及与 Java 相关的，一般也会用子进程去操作。这样即使出现二次崩溃，只是这部分的信息丢失，我们的父进程后面还可以继续获取其他的信息。在一些特殊的情况，我们还可能需要从子进程 fork 出孙进程。当然 Breakpad 也存在着一些问题，例如生成的 minidump 文件是二进制格式的，包含了太多不重要的信息，导致文件很容易达到几 MB。我们有时候要去改造 Breakpad 的实现。比较常见的例如增加 Logcat 信息、Java 调用栈信息以及崩溃时的其他一些有用信息。

## 三、异常退出的情况

1）主动自杀：Process.killProcess()、exit() 等。

2）崩溃：出现了 Java 或 Native 崩溃。

3）系统重启：系统出现异常、断电、用户主动重启等，我们可以通过比较应用开机运行时间是否比之前记录的值更小。

4）被系统杀死：被 low memory killer 杀掉、从系统的任务管理器中划掉等。

5）ANR, 我们会开专栏分析，这里不再赘述

应对：我们可以在应用启动的时候设定一个标志，在主动自杀或崩溃后更新标志，这样下次启动时通过检测这个标志就能确认运行期间是否发生过异常退出。

根据应用的前后台状态，我们可以把异常退出分为前台异常退出和后台异常退出。“被系统杀死”是后台异常退出的主要原因，当然我们会更关注前台的异常退出的情况，这会跟 ANR、OOM 等异常情况有更大的关联。

## 四、崩溃现场

崩溃现场保留着很多有价值的线索，是我们解决问题的重要信息，丰富和准确的崩溃现场能够帮助我们快速解决问题，接下来主要看看崩溃现场通常需要采集哪些信息。
1）崩溃信息
- 进程名、线程名
- 崩溃堆栈和类型。崩溃是属于Java崩溃、Native崩溃，还是ANR，对于不同的类型我们的关注点不同,特别需要看崩溃堆栈的信息，看具体崩溃在系统的代码，还是我们自己的代码里面。

2）系统信息
- Logcat。这里包含应用、系统的运行日志。由于系统权限问题，获取到的 Logcat 可能只包含与当前 App 相关的。其中系统的 event logcat 会记录 App 运行的一些基本情况，记录在文件 /system/etc/event-log-tags 中。
- 机型、系统、厂商、CPU、ABI、Linux版本等
- 设备状态，是否Root，是否为模拟器等

3）内存信息
- 系统剩余内存。关于系统内存状态，可以直接读取文件 /proc/meminfo
- 应用使用内存， 包括Java内存、RSS（Resident Set Size)、PSS（Proportional Set Size)
- 虚拟内存。虚拟内存可以通过 /proc/self/status 得到，通过 /proc/self/maps 文件可以得到具体的分布情况

4）资源信息
- 文件句柄fd。文件句柄的限制可以通过 /proc/self/limits 获得，一般单个进程允许打开的最大文件句柄个数为 1024。
- 线程数。当前线程数大小可以通过上面的 status 文件得到，一个线程可能就占 2MB 的虚拟内存。
- JNI。我们可以通过 DumpReferenceTables 统计 JNI 的引用表，进一步分析。

5）应用信息
- 崩溃场景，发生在哪个Activity或Fragment，发生在哪个业务中
- 关键操作路径，通过打点，记录用户的关键操作路径
- 其他自定义信息

## 五、崩溃分析

### 第一步：确定重点

a、确认严重程度。优先解决 Top 崩溃或者对业务有重大影响，例如启动、支付过程的崩溃

b、崩溃基本信息

- Java崩溃，常见NullPointerException空指针，OutOfMemoryError资源不足
- Native崩溃，需要观察signal、code、fault addr等内容，以及崩溃时的Java的堆栈。
- ANR，检查主线程是否有耗时操作，是否因为锁等地导致，再观察iowait、CPU、GC、system sever等信息。进一步确认是I/O问题，或者是CPU竞争，还是大量GC导致的

c、Locat，日志包含了大量有用的信息，可以尝试分析，不放过任何问题

d、各个资源情况，综合所有信息，分析原因

### 第二步：查找共性

  比如机型、系统、厂商、CPUD等是否有相同点

### 第三步：尝试复现

  能够复现的崩溃，就可以获得更多的现场信息，也会更加容易发现问题

## 六、疑难问题

​    有些崩溃可能跟app无关，而是系统版本或产商room的问题，这就很难直接定位问题。

- 查找可能的原因
- 尝试规避
- Hook解决。关键在寻找Hook点，关于hook，我们在插件板块再详细介绍

总结：

崩溃攻防是一个长期的过程，我们希望尽可能地提前预防崩溃的发生，将它消灭在萌芽阶段。这可能涉及我们应用的整个流程，包括人员的培训、编译检查、静态扫描工作，还有规范的测试、灰度、发布流程等

**附加示例** ：

如果想向崩溃发起挑战，那么 Top 20 崩溃就是我们无法避免的对手。在这里面会有不少疑难的系统崩溃问题，TimeoutException 就是其中比较经典的一个。

```
java.util.concurrent.TimeoutException: android.os.BinderProxy.finalize() timed out after 10 secondsat android.os.BinderProxy.destroy(Native Method)at android.os.BinderProxy.finalize(Binder.java:459)
```

 [Sample](https://github.com/AndroidAdvanceWithGeektime/Chapter02)提供了一种“完全解决”TimeoutException 的方法，主要是希望你可以更好地学习解决系统崩溃的套路。

1. 通过源码分析。我们发现 TimeoutException 是由系统的 FinalizerWatchdogDaemon 抛出来的。


2. 寻找可以规避的方法。尝试调用了它的 Stop() 方法，但是线上发现在 Android 6.0 之前会有线程同步问题。
3. 寻找其他可以 Hook 的点。通过代码的依赖关系，发现一个取巧的 Hook 点。



## 参考：

1. [Android开发高手课](https://time.geekbang.org/column/article/70602)








